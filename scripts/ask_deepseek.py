#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç»„åˆæ£€ç´¢ + DeepSeek ç”Ÿæˆå›ç­”
éœ€è¦ç¯å¢ƒå˜é‡ï¼š
  DEESEEK_API_KEY   DeepSeek è´¦æˆ·çš„ API Key
"""

import os, textwrap, json
from pathlib import Path

from openai import OpenAI
from scripts.retrieve_chunks import search 
from dotenv import load_dotenv
import json
import re


load_dotenv() 



DEESEEK_BASE_URL = "https://api.deepseek.com"
MODEL_NAME       = "deepseek-chat"
TEMPERATURE      = 0.3
TOP_K_CONTEXT    = 5 

client = OpenAI(
    api_key=os.getenv("DEESEEK_API_KEY"),
    base_url=DEESEEK_BASE_URL
)

def parse_json_from_llm(raw_text: str):
    # å»é™¤ ```json æˆ– ``` åŒ…è£¹
    cleaned = re.sub(r"^```(?:json)?\s*", "", raw_text.strip())
    cleaned = re.sub(r"\s*```$", "", cleaned)
    return json.loads(cleaned)

def rewrite_query_with_deepseek(question: str) -> str:
    prompt = f"""è¯·å°†ä»¥ä¸‹é—®é¢˜æ”¹å†™ä¸ºæ›´é€‚åˆæ£€ç´¢æ–‡æ¡£çš„è¡¨è¾¾æ–¹å¼ï¼Œä½¿å…¶æ›´æ¸…æ™°ã€å…·ä½“ï¼Œå¹¶å°½å¯èƒ½è´´è¿‘æ–‡æ¡£ä¸­å¯èƒ½å‡ºç°çš„è¡¨è¿°é£æ ¼ï¼š
è¯·æ³¨æ„ï¼Œä½ è¾“å‡ºçš„ç»“æœæˆ‘ä¼šç›´æ¥ç”¨äºembed æ¨¡å‹çš„æ£€ç´¢ï¼Œæ‰€ä»¥è¯·ç¡®ä¿æ”¹å†™åçš„é—®é¢˜èƒ½å¤Ÿæ›´å¥½åœ°åŒ¹é…æ–‡æ¡£å†…å®¹ï¼Œä¸éœ€è¦æ›´å¤šçš„è§£é‡Šã€‚    
åŸå§‹é—®é¢˜ï¼š{question}
é‡å†™åï¼š"""

    response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
    return response.choices[0].message.content.strip()


def build_prompt(question: str, context_chunks: list[dict]) -> str:
    context_text = "\n\n".join(
        f"ã€å‡ºå¤„ï¼š{c['source_file']}#{c['chunk_index']}ã€‘\n{c['text']}"
        for c in context_chunks
    )
    return textwrap.dedent(f"""\
        è¯·ç»“åˆä»¥ä¸‹èµ„æ–™å›ç­”é—®é¢˜ï¼Œå¹¶ä»¥ JSON æ ¼å¼è¿”å›ï¼š

        {{
        "answer": "...",
        "citations": [
            {{
            "source": "xxx.txt#3",
            "quote": "è¢«å¼•ç”¨çš„åŸæ–‡å†…å®¹"
            }},
            ...
        ]
        }}

        èµ„æ–™å¦‚ä¸‹ï¼š
        {context_text}

        é—®é¢˜ï¼š{question}
        """)


def ask(question: str):
    rewritten = rewrite_query_with_deepseek(question)
    print(f"\nğŸ“ é‡å†™åçš„æ£€ç´¢é—®é¢˜ï¼š{rewritten}\n")
    chunks = search(rewritten, TOP_K_CONTEXT)
    prompt = build_prompt(question, chunks)
    response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": prompt}],
        temperature=TEMPERATURE
    )
    raw_content = response.choices[0].message.content.strip()

    try:
        parsed = parse_json_from_llm(raw_content)

        answer = parsed["answer"]
        citations = parsed.get("citations", []) 
    except json.JSONDecodeError:
        print("âŒ æ— æ³•è§£æä¸º JSONï¼Œè¿”å›åŸå§‹å†…å®¹")
        answer = raw_content
        citations = []
    
    return answer, chunks, citations


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Ask with RAG + DeepSeek")
    parser.add_argument("question", nargs="+", help="è¦æé—®çš„é—®é¢˜")
    args = parser.parse_args()

    q = " ".join(args.question)
    answer, used_chunks = ask(q)

    print("\n=== ğŸ¯ ç­”æ¡ˆ ===\n")
    print(answer)

    print("\n=== ğŸ“‘ å¼•ç”¨çš„æ–‡æ¡£æ®µè½ (top-k) ===")
    for c in used_chunks:
        print(f"- {c['source_file']}#{c['chunk_index']} (dist={c['distance']:.4f})")
